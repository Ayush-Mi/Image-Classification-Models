{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Numpy and Pandas are used to \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Below libraries are used for general operations\n",
    "import os\n",
    "from glob import glob\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "#Used for selecting image files for train and test folder\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Image Data Generator is used to load image sequentially \n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "#Loading Model Parameters from Keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "\n",
    "#Confusion Matrix used for evaluation\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "#Callback is used to save the best model by monitoring Val accuracy\n",
    "from keras import callbacks\n",
    "\n",
    "#Importing pre trained model architecture \n",
    "from keras.applications.resnet50 import ResNet50\n",
    "from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#To read the sved model\n",
    "from keras.models import model_from_json\n",
    "\n",
    "#The model optimizer\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = os.getcwd()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating Train and Test directories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(path +'/Binary_data/Train/Positive')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(path +'/Binary_data/Train/Negative')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(path +'/Binary_data/Test/Positive')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.makedirs(path +'/Binary_data/Test/Negative')\n",
    "except FileExistsError:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting and moving image files into Train and Test folders created above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pos, test_pos = train_test_split(os.listdir(path+'/Binary_data/Positive/'),test_size=0.1, random_state=1)\n",
    "train_neg, test_neg = train_test_split(os.listdir(path+'/Binary_data/Negative/'),test_size=0.1, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_train_pos = [shutil.copy(path+'/Binary_data/Positive/'+x,path+'/Binary_data/Train/Positive/') for x in train_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_test_pos = [shutil.copy(path+'/Binary_data/Positive/'+x,path+'/Binary_data/Test/Positive/') for x in test_pos]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_train_neg = [shutil.copy(path+'/Binary_data/Negative/'+x,path+'/Binary_data/Train/Negative/') for x in train_neg]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_test_neg = [shutil.copy(path+'/Binary_data/Negative/'+x,path+'/Binary_data/Test/Negative/') for x in test_neg]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using ImageDataGenerator to pass image files in batches to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "        rotation_range=40,\n",
    "        width_shift_range=0,\n",
    "        height_shift_range=0,\n",
    "        rescale=1./255,\n",
    "        shear_range=0,\n",
    "        zoom_range=0,\n",
    "        horizontal_flip=False,\n",
    "        validation_split=0.2,\n",
    "        fill_mode='nearest')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 28800 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "train_path = path +'/Binary_data/Train'\n",
    "\n",
    "train_generator = datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset=\"training\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = datagen.flow_from_directory(\n",
    "        train_path,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',\n",
    "        subset=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom CNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining the custom CNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:3376: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/tensorflow_core/python/ops/nn_impl.py:183: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(150, 150,3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 150, 150, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 150, 150, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 75, 75, 32)        9248      \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 75, 75, 32)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 38, 38, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 38, 38, 64)        18496     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 38, 38, 64)        0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 19, 19, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 23104)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 64)                1478720   \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 1,507,425\n",
      "Trainable params: 1,507,425\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"cnn_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path + '/cnn_checkpoint'\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:2741: The name tf.Session is deprecated. Please use tf.compat.v1.Session instead.\n",
      "\n",
      "Epoch 1/15\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:190: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:199: The name tf.is_variable_initialized is deprecated. Please use tf.compat.v1.is_variable_initialized instead.\n",
      "\n",
      "WARNING:tensorflow:From /opt/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py:206: The name tf.variables_initializer is deprecated. Please use tf.compat.v1.variables_initializer instead.\n",
      "\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.4982 - acc: 0.8135 - val_loss: 0.1660 - val_acc: 0.9500\n",
      "Epoch 2/15\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.1405 - acc: 0.9605 - val_loss: 0.1801 - val_acc: 0.9675\n",
      "Epoch 3/15\n",
      "125/125 [==============================] - 39s 308ms/step - loss: 0.1684 - acc: 0.9615 - val_loss: 0.0911 - val_acc: 0.9762\n",
      "Epoch 4/15\n",
      "125/125 [==============================] - 36s 291ms/step - loss: 0.1331 - acc: 0.9690 - val_loss: 0.2038 - val_acc: 0.9375\n",
      "Epoch 5/15\n",
      "125/125 [==============================] - 36s 289ms/step - loss: 0.2141 - acc: 0.9635 - val_loss: 0.0732 - val_acc: 0.9838\n",
      "Epoch 6/15\n",
      "125/125 [==============================] - 36s 284ms/step - loss: 0.7212 - acc: 0.9410 - val_loss: 0.0495 - val_acc: 0.9862\n",
      "Epoch 7/15\n",
      "125/125 [==============================] - 36s 286ms/step - loss: 0.1387 - acc: 0.9730 - val_loss: 0.0500 - val_acc: 0.9900\n",
      "Epoch 8/15\n",
      "125/125 [==============================] - 35s 281ms/step - loss: 0.1727 - acc: 0.9675 - val_loss: 0.1177 - val_acc: 0.9825\n",
      "Epoch 9/15\n",
      "125/125 [==============================] - 36s 290ms/step - loss: 2.9374 - acc: 0.7990 - val_loss: 8.2701 - val_acc: 0.4813\n",
      "Epoch 10/15\n",
      "125/125 [==============================] - 41s 330ms/step - loss: 8.1625 - acc: 0.4880 - val_loss: 8.3299 - val_acc: 0.4775\n",
      "Epoch 11/15\n",
      "125/125 [==============================] - 45s 363ms/step - loss: 4.7159 - acc: 0.6965 - val_loss: 0.0690 - val_acc: 0.9900\n",
      "Epoch 12/15\n",
      "125/125 [==============================] - 41s 325ms/step - loss: 4.5542 - acc: 0.7015 - val_loss: 8.0310 - val_acc: 0.4963\n",
      "Epoch 13/15\n",
      "125/125 [==============================] - 39s 315ms/step - loss: 7.8835 - acc: 0.5055 - val_loss: 7.7918 - val_acc: 0.5112\n",
      "Epoch 14/15\n",
      "125/125 [==============================] - 38s 304ms/step - loss: 8.1705 - acc: 0.4875 - val_loss: 7.5128 - val_acc: 0.5288\n",
      "Epoch 15/15\n",
      "125/125 [==============================] - 39s 310ms/step - loss: 7.7639 - acc: 0.5130 - val_loss: 7.9712 - val_acc: 0.5000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14f248110>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=15,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size,\n",
    "        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model.save_weights('cnn_binary_classification.h5')  # always save your weights after training or during training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(\n",
    "    rotation_range=0,\n",
    "    width_shift_range=0,\n",
    "    height_shift_range=0,\n",
    "    rescale=1./255,\n",
    "    shear_range=0,\n",
    "    zoom_range=0,\n",
    "    fill_mode='nearest')\n",
    "\n",
    "test_path = path + \"/Binary_data/Test\"\n",
    "test_generator = datagen.flow_from_directory(\n",
    "        test_path,  # this is the target directory\n",
    "        target_size=(150, 150),  # all images will be resized to 150x150\n",
    "        batch_size=batch_size,\n",
    "        class_mode='binary',shuffle=False)\n",
    "\n",
    "def test_model(model_path,model_weights):\n",
    "    \n",
    "    json_file = open(model_path, 'r')\n",
    "    loaded_model_json = json_file.read()\n",
    "    json_file.close()\n",
    "    \n",
    "    loaded_model = model_from_json(loaded_model_json)\n",
    "    \n",
    "    loaded_model.load_weights(model_weights)\n",
    "    \n",
    "    probabilities = loaded_model.predict_generator(test_generator,steps=len(test_generator))\n",
    "    \n",
    "    y_true = test_generator.classes\n",
    "    y_pred = probabilities >0.5\n",
    "    \n",
    "    cnf_matrix = confusion_matrix(y_pred,y_true)\n",
    "    \n",
    "    score = (cnf_matrix[0][0] + cnf_matrix[1][1])/y_pred.shape[0]\n",
    "    \n",
    "    return cnf_matrix,score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_cnn, score_cnn = test_model('cnn_model.json','cnn_checkpoint')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with custom CNN model: 0.981\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with custom CNN model: {}\".format(score_cnn))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1978,   54],\n",
       "       [  22, 1946]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ResNet50 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/keras_applications/resnet50.py:265: UserWarning: The output shape of `ResNet50(include_top=False)` has been changed since Keras 2.2.0.\n",
      "  warnings.warn('The output shape of `ResNet50(include_top=False)` '\n"
     ]
    }
   ],
   "source": [
    "base_model = ResNet50(include_top= False,input_shape=(150,150,3),weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for layers in base_model.layers[:]:\\n    layers.trainable = False'"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for layers in base_model.layers[:]:\n",
    "    layers.trainable = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop(lr=0.0001)\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "resnet50 (Model)             (None, 5, 5, 2048)        23587712  \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 5, 5, 32)          589856    \n",
      "_________________________________________________________________\n",
      "activation_381 (Activation)  (None, 5, 5, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_29 (MaxPooling (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 3, 3, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_382 (Activation)  (None, 3, 3, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_30 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 2, 2, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_383 (Activation)  (None, 2, 2, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_31 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_9 (Flatten)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_384 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_385 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 24,209,537\n",
      "Trainable params: 24,156,417\n",
      "Non-trainable params: 53,120\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"resnet50_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path + '/resnet50_chkpnt'\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 412s 3s/step - loss: 0.1167 - acc: 0.9600 - val_loss: 0.0210 - val_acc: 0.9925\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 361s 3s/step - loss: 0.0386 - acc: 0.9920 - val_loss: 0.0176 - val_acc: 0.9938\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 359s 3s/step - loss: 0.0460 - acc: 0.9870 - val_loss: 0.0040 - val_acc: 0.9988\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 362s 3s/step - loss: 0.0453 - acc: 0.9915 - val_loss: 0.1461 - val_acc: 0.9850\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 353s 3s/step - loss: 0.0708 - acc: 0.9920 - val_loss: 0.0038 - val_acc: 0.9975\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x196f1f790>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size,\n",
    "        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing the Resnet50 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_res, score_res = test_model(\"resnet50_model.json\",'resnet50_chkpnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with Resnet50 model: 0.99775\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy with Resnet50 model: {}\".format(score_res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1996,    5],\n",
       "       [   4, 1995]])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VGG16 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = VGG16(include_top= False,input_shape=(150,150,3),weights='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'for layers in base_model.layers[:]:\\n    layers.trainable = False'"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''for layers in base_model.layers[:]:\n",
    "    layers.trainable = False'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(base_model)\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3),padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2),padding='same'))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = RMSprop()\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "vgg16 (Model)                (None, 4, 4, 512)         14714688  \n",
      "_________________________________________________________________\n",
      "conv2d_31 (Conv2D)           (None, 4, 4, 32)          147488    \n",
      "_________________________________________________________________\n",
      "activation_396 (Activation)  (None, 4, 4, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_38 (MaxPooling (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_32 (Conv2D)           (None, 2, 2, 32)          9248      \n",
      "_________________________________________________________________\n",
      "activation_397 (Activation)  (None, 2, 2, 32)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_39 (MaxPooling (None, 1, 1, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 1, 1, 64)          18496     \n",
      "_________________________________________________________________\n",
      "activation_398 (Activation)  (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_40 (MaxPooling (None, 1, 1, 64)          0         \n",
      "_________________________________________________________________\n",
      "flatten_12 (Flatten)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 64)                4160      \n",
      "_________________________________________________________________\n",
      "activation_399 (Activation)  (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 65        \n",
      "_________________________________________________________________\n",
      "activation_400 (Activation)  (None, 1)                 0         \n",
      "=================================================================\n",
      "Total params: 14,894,145\n",
      "Trainable params: 14,894,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "\n",
    "with open(\"vgg16_model.json\", \"w\") as json_file:\n",
    "    json_file.write(model_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_filepath = path + '/vgg16_chkpnt'\n",
    "model_checkpoint_callback = callbacks.ModelCheckpoint(\n",
    "    filepath=checkpoint_filepath,\n",
    "    save_weights_only=True,\n",
    "    monitor='val_acc',\n",
    "    mode='max',\n",
    "    save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "125/125 [==============================] - 345s 3s/step - loss: 7.8591 - acc: 0.5030 - val_loss: 7.9911 - val_acc: 0.4988\n",
      "Epoch 2/5\n",
      "125/125 [==============================] - 327s 3s/step - loss: 7.7020 - acc: 0.5170 - val_loss: 8.4495 - val_acc: 0.4700\n",
      "Epoch 3/5\n",
      "125/125 [==============================] - 339s 3s/step - loss: 7.8936 - acc: 0.5050 - val_loss: 7.4331 - val_acc: 0.5337\n",
      "Epoch 4/5\n",
      "125/125 [==============================] - 352s 3s/step - loss: 8.1800 - acc: 0.4870 - val_loss: 7.6723 - val_acc: 0.5188\n",
      "Epoch 5/5\n",
      "125/125 [==============================] - 346s 3s/step - loss: 7.8223 - acc: 0.5095 - val_loss: 8.1306 - val_acc: 0.4900\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1df233a10>"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "        train_generator,\n",
    "        steps_per_epoch=2000 // batch_size,\n",
    "        epochs=5,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=800 // batch_size,\n",
    "        callbacks=[model_checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnf_matrix_vgg ,score_vgg = test_model('vgg16_model.json','vgg16_chkpnt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy with VGG16 model: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('Accuracy with VGG16 model: {}'.format(score_vgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   0,    0],\n",
       "       [2000, 2000]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cnf_matrix_vgg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN: 0.981 , Resnet50: 0.99775, VGG16: 0.5\n"
     ]
    }
   ],
   "source": [
    "print('CNN: {} , Resnet50: {}, VGG16: {}'.format(score_cnn,score_res,score_vgg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.4 64-bit ('base': conda)",
   "language": "python",
   "name": "python37464bitbaseconda2c94488eb95f40cd9e0f1bec08584c61"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
